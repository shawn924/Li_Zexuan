# ğŸ“¦ Olist Project

## ğŸš€ Project Overview

The **Olist Project** is an e-commerce data analysis and visualization project. It analyzes orders, delays, and regional distribution to uncover business insights.

**Key Questions:**
1. What % of orders are delivered late?
2. Which regions (states/cities) have the longest delivery times?
3. How do delivery delays affect customer review scores?
4. Which product categories generate the highest revenue?
5. Which sellers have the highest sales volume and best customer ratings?

**Workflow:**

* Load raw data into **PostgreSQL**
* Analyze data using **SQL**
* Visualize results with **Power BI** (PDF export)

## ğŸ›  Tech Stack

* **Database:** PostgreSQL (Docker Compose)
* **Data Loading:** Python (`load_data_into_postgres.py`)
* **Data Analysis:** SQL
* **Visualization:** Power BI (PDF export)
* **Dependency Management:** `.gitignore`

## ğŸ“ Project Structure

* `sql/`

  * `late_orders.sql` â€” Analyze delayed orders
  * `delay_by_state.sql` â€” Analyze delays by state
  * Other SQL scripts
* `docker-compose.yml` â€” PostgreSQL configuration
* `load_data_into_postgres.py` â€” Python data loader
* `log.md` â€” Notes
* `olist-analysis.pdf` â€” Power BI exported PDFs
* `.gitignore` â€” Ignored files
* `README.md` â€” Project documentation

## ğŸ” Data Analysis Workflow

1. **Set up the Database**

```bash
docker-compose up -d
```

2. **Load Data**

```bash
python load_data_into_postgres.py
```

3. **SQL Analysis**

```sql
\i sql/late_orders.sql;
\i sql/delay_by_state.sql;
```

4. **Visualization**

* Import SQL query results into Power BI
* Create dashboards
* Export as PDF into `visualization/`

## ğŸ“Š Data Source

* [Olist Brazilian E-commerce Dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)
* Includes orders, customers, products, and geographical information

## âš ï¸ Notes

* Power BI Desktop cannot generate shareable links; use PDF for visualization
* Ensure PostgreSQL credentials in `load_data_into_postgres.py` are correct
* Maintain the project folder structure for smooth execution

## ğŸ¤ Contributing

* Fork the repository
* Submit changes via Pull Request

## ğŸ“„ License

MIT License
